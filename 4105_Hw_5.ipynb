{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/c4HfLWKuc/bqRh+mkinu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pathin220/4105_ML/blob/main/4105_Hw_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import tensorflow\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "t8ZemFFSoF8-"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "ehLRpXAls-6I"
      },
      "outputs": [],
      "source": [
        "#1. In our temperature prediction example, letâ€™s change our model to a nonlinear system. Consider the following description for our model:\n",
        "\n",
        "#w2 * t_u ** 2 + w1 * t_u + b.\n",
        "\n",
        "#1.a Modify the training loop properly to accommodate this redefinition.\n",
        "\n",
        "#1.b Use 5000 epochs for your training. Explore different learning rates from 0.1 to 0.0001 (you need four separate trainings).\n",
        "#Report your loss for every 500 epochs per training.\n",
        "\n",
        "#1.c Pick the best non-linear model and compare your final best loss against the linear model that we did during the lecture.\n",
        "#For this, visualize the non-linear model against the linear model over the input dataset, as we did during the lecture. Is the actual result better or worse than our baseline linear model?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#setting values in array for X which is t_C and Y which is t_U\n",
        "t_c = [0.5, 14.0, 15.0, 28.0, 11.0, 8.0, 3.0, -4.0, 6.0, 13.0, 21.0]\n",
        "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]\n",
        "t_c = torch.tensor(t_c)\n",
        "t_u = torch.tensor(t_u)\n",
        "t_un = 0.1 * t_u"
      ],
      "metadata": {
        "id": "GEBuSs8aoFQ-"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(t_c)\n",
        "print(t_u)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RT2tGXWfp_QR",
        "outputId": "cdb15c24-6991-4569-b2ec-06fa42629c48"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.5000, 14.0000, 15.0000, 28.0000, 11.0000,  8.0000,  3.0000, -4.0000,\n",
            "         6.0000, 13.0000, 21.0000])\n",
            "tensor([35.7000, 55.9000, 58.2000, 81.9000, 56.3000, 48.9000, 33.9000, 21.8000,\n",
            "        48.4000, 60.4000, 68.4000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#defining the nonlinear model\n",
        "def nonlin_model(t_u, w2, w1, b):\n",
        "    return w2 * t_u**2 + w1 * t_u + b"
      ],
      "metadata": {
        "id": "5rbiJQw8qyQa"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining the linear model\n",
        "def lin_model(t_u, w, b):\n",
        "    return w * t_u + b"
      ],
      "metadata": {
        "id": "lbbwi_GFs2Y9"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(t_p, t_c):\n",
        "    squared_diffs = (t_p - t_c)**2\n",
        "    return squared_diffs.mean()"
      ],
      "metadata": {
        "id": "nYs1iyJhr2YT"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "w2 = torch.ones(())\n",
        "w1 = torch.ones(())\n",
        "b = torch.zeros(())\n",
        "\n",
        "t_p = nonlin_model(t_u, w2, w1, b)\n",
        "t_p"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuwPIB0vsU8N",
        "outputId": "543fb76f-344e-425b-8181-cc1450a4d53e"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1310.1901, 3180.7100, 3445.4399, 6789.5103, 3225.9900, 2440.1101,\n",
              "        1183.1101,  497.0399, 2390.9600, 3708.5601, 4746.9600])"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#computing the loss\n",
        "loss = loss_fn(t_p, t_c)\n",
        "loss\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xPeTxRjw9rr",
        "outputId": "cbaa72da-d8d2-4f70-f2e7-b26ade56d5b4"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(11709471.)"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Non-linear training loop\n",
        "def training_loop (n_epochs, optimizer, params, t_u, t_c, learning_rate):\n",
        "    print(f'Learning Rate: {learning_rate}')\n",
        "    for epoch in range(1, n_epochs+1):\n",
        "        w1, w2, b = params\n",
        "        t_p = nonlin_model (t_u, w1, w2, b)\n",
        "        loss = loss_fn(t_p, t_c)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if epoch % 500 == 0:\n",
        "            print ('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
        "    return params, loss"
      ],
      "metadata": {
        "id": "gNEciijVtMIW"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear training loop\n",
        "def lin_training_loop (n_epochs, optimizer, params, t_u, t_c):\n",
        "    for epoch in range(1, n_epochs+1):\n",
        "        t_p = lin_model (t_u, *params)\n",
        "        loss = loss_fn(t_p, t_c)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if epoch % 500 == 0:\n",
        "            print ('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
        "    return params, loss"
      ],
      "metadata": {
        "id": "QQwRckuNyLaL"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7HgRM8IP3KM1"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = [0.1, 0.01, 0.001, 0.0001]\n",
        "train_params = torch.zeros(len(learning_rate), 3)\n",
        "train_loss = torch.zeros(len(learning_rate), 1)\n",
        "linear_train_params = torch.zeros(1, 2)\n",
        "linear_train_loss = torch.zeros(1, 1)\n",
        "\n"
      ],
      "metadata": {
        "id": "CGdfTe5b144w"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in learning_rate:\n",
        "    params = torch.tensor([1.0, 1.0, 0.0], requires_grad=True)\n",
        "    optimizer = optim.SGD([params], lr=i)\n",
        "\n",
        "    train_params[learning_rate.index(i)], train_loss[learning_rate.index(i)] = training_loop(\n",
        "        n_epochs = 5000,\n",
        "        optimizer = optimizer,\n",
        "        params = params,\n",
        "        t_u = t_un,\n",
        "        t_c = t_c,\n",
        "        learning_rate = i\n",
        "        )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLpD-Uf72Ugv",
        "outputId": "862301a3-32d5-4471-f2dc-ce07a1789c58"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning Rate: 0.1\n",
            "Epoch 500, Loss nan\n",
            "Epoch 1000, Loss nan\n",
            "Epoch 1500, Loss nan\n",
            "Epoch 2000, Loss nan\n",
            "Epoch 2500, Loss nan\n",
            "Epoch 3000, Loss nan\n",
            "Epoch 3500, Loss nan\n",
            "Epoch 4000, Loss nan\n",
            "Epoch 4500, Loss nan\n",
            "Epoch 5000, Loss nan\n",
            "Learning Rate: 0.01\n",
            "Epoch 500, Loss nan\n",
            "Epoch 1000, Loss nan\n",
            "Epoch 1500, Loss nan\n",
            "Epoch 2000, Loss nan\n",
            "Epoch 2500, Loss nan\n",
            "Epoch 3000, Loss nan\n",
            "Epoch 3500, Loss nan\n",
            "Epoch 4000, Loss nan\n",
            "Epoch 4500, Loss nan\n",
            "Epoch 5000, Loss nan\n",
            "Learning Rate: 0.001\n",
            "Epoch 500, Loss nan\n",
            "Epoch 1000, Loss nan\n",
            "Epoch 1500, Loss nan\n",
            "Epoch 2000, Loss nan\n",
            "Epoch 2500, Loss nan\n",
            "Epoch 3000, Loss nan\n",
            "Epoch 3500, Loss nan\n",
            "Epoch 4000, Loss nan\n",
            "Epoch 4500, Loss nan\n",
            "Epoch 5000, Loss nan\n",
            "Learning Rate: 0.0001\n",
            "Epoch 500, Loss 10.708596\n",
            "Epoch 1000, Loss 8.642083\n",
            "Epoch 1500, Loss 7.171005\n",
            "Epoch 2000, Loss 6.123478\n",
            "Epoch 2500, Loss 5.377227\n",
            "Epoch 3000, Loss 4.845286\n",
            "Epoch 3500, Loss 4.465788\n",
            "Epoch 4000, Loss 4.194724\n",
            "Epoch 4500, Loss 4.000802\n",
            "Epoch 5000, Loss 3.861744\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lin_params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
        "learning_rate = 0.0001\n",
        "optimizer = optim.SGD([lin_params], lr=learning_rate)\n",
        "print(f'Linear model with LR={learning_rate}')\n",
        "lin_train_params, lin_train_loss = lin_training_loop(\n",
        "    n_epochs = 5000,\n",
        "    optimizer = optimizer,\n",
        "    params = lin_params,\n",
        "    t_u = t_un,\n",
        "    t_c = t_c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rv1-PbFs4WIz",
        "outputId": "ecc4c9bd-b712-4d4f-b0bf-f3737c4974f7"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear model with LR=0.0001\n",
            "Epoch 500, Loss 29.505890\n",
            "Epoch 1000, Loss 28.943773\n",
            "Epoch 1500, Loss 28.505281\n",
            "Epoch 2000, Loss 28.074451\n",
            "Epoch 2500, Loss 27.650877\n",
            "Epoch 3000, Loss 27.234444\n",
            "Epoch 3500, Loss 26.825020\n",
            "Epoch 4000, Loss 26.422493\n",
            "Epoch 4500, Loss 26.026745\n",
            "Epoch 5000, Loss 25.637672\n"
          ]
        }
      ]
    }
  ]
}